--- 
# tasks for hosts in cluster_hosts group
# tasks run vi ssh (using keys, no passwords)
# 
- hosts: cluster_hosts
  become: true
  become_user: root 
  vars_files: 
  - /etc/ansible/vars.yaml

  tasks: # sections: yum_update, setup_etc_hosts, setup_repos, 
         #           setup_java, setup_spark, setup_hadoop, setup_dse
 
  # update all yum packages
  #
# - name: yum update
#   yum: name='*'
#        state=latest
#   tags: 
#   - yum_update
#   - setup_basics
#
#

  - name: set hostname to fqdn
    command: 'hostname {{hostvars[inventory_hostname].fqdn}}'
    tags: 
    - setup_hostname
    - setup_basics

  - name: add boxes to /etc/hosts 
    lineinfile: name=/etc/hosts
      line='{{hostvars[item].ip}}  {{hostvars[item].name}} {{hostvars[item].fqdn}}'
      insertafter=
    with_items: "{{groups['cluster_hosts']}}" 
    tags: 
    - setup_etc_hosts
    - setup_basics

  # section: setup_repos 
  #
  - name: disribute {{download_dir}}/yum.repos.d/* to /etc/yum.repos.d/
    copy: src={{download_dir}}/yum.repos.d/
          dest=/etc/yum.repos.d/
    tags: 
    - setup_repos
    - setup_basics

# - name: distribute /opt/dse-repo/ 
#   copy: src=/opt/dse-repo/
#         dest=/opt/dse-repo/
#   tags: 
#   - setup_repos
#   - setup_basics

  # section: setup_java
  #
  # Java 1.8
  - name: unarchive java 1.8 into /opt
    unarchive: src={{java18_file}}
               dest=/opt
               owner=root group=root mode=0755
    tags: 
    - setup_java18
    - setup_basics

  - name: alternatives java 1.8
    command: sudo alternatives --install /usr/bin/java java {{java18_dir}}/bin/java 1
    tags: 
    - setup_java18
    - setup_basics

  - name: alternatives javac 1.8
    command: sudo alternatives --install /usr/bin/javac javac {{java18_dir}}/bin/javac 1
    tags: 
    - setup_java18
    - setup_basics

  - name: alternatives jar 1.8
    command: sudo alternatives --install /usr/bin/jar jar {{java18_dir}}/bin/jar 1
    tags: 
    - setup_java18
    - setup_basics

  - name: set JAVA_HOME in /etc/profile.d/local.sh
    lineinfile: dest={{profile_file}}
        regexp="export JAVA_HOME"
        line="export JAVA_HOME={{java18_dir}}"
        insertafter=EOF
        create=yes
    tags: 
    - setup_java18
    - setup_basics

  # Java 1.7
  - name: unarchive java 1.7 into /opt
    unarchive: src=/vagrant/Tarballs/{{java17_file}}
               dest=/opt/
               owner=root group=root mode=0755
    tags: 
    - setup_java17

  - name: alternatives java 1.7
    command: sudo alternatives --install /usr/bin/java java {{java17_dir}}/bin/java 2
    tags: 
    - setup_java17

  - name: alternatives javac 1.7
    command: sudo alternatives --install /usr/bin/javac javac {{java17_dir}}/bin/javac 2
    tags: 
    - setup_java17

  - name: alternatives jar 1.7
    command: sudo alternatives --install /usr/bin/jar jar {{java17_dir}}/bin/jar 2
    tags: 
    - setup_java17


  # section: setup_spark
  #
  # - name: copy spark
  #   copy: src=/vagrant/Tarballs/{{spark_file}}
  #         dest=/opt/Tarballs/
  #   tags: setup_spark

  - name: spark_archive
    debug: msg="{{spark_archive}}"
    tags: test

  - name: unarchive spark into /opt
    unarchive: src={{spark_archive}}
               dest=/opt/
               owner=root group=root mode=0755
    tags: 
    - test
    - setup_spark 

  - name: copy spark-cassandra-connector.jar to {{spark_dir}}/lib/
    copy: src=/vagrant/spark-cassandra-connector.jar
          dest={{spark_dir}}/lib/
    tags: setup_spark

  - name: create {{spark_dir}}/conf/spark-defaults.conf
    lineinfile: dest={{spark_dir}}/conf/spark-defaults.conf
                regexp="this string is not in the file"
                line="{{item}}"
                insertafter=EOF
                create=yes
                mode=0755
    with_items: 
    - "spark.master            spark://{{spark_master_host}}:7077"
    - "spark.executor.memory   512m"
    tags: setup_spark

  - name: create /usr/local/bin/spark-shell
    copy: dest=/usr/local/bin/spark-shell
          content="{{spark_cmd}}"
          mode=0755
    tags: setup_spark

  - name: create lib/spark-shell-startup
    lineinfile: dest={{spark_dir}}/lib/spark-shell-startup
                line="{{item}}"
                insertafter=EOF
                create=yes
                mode=0755
    with_items:
    - 'import com.datastax.spark.connector._'
    - 'import org.apache.spark.SparkContext'
    - 'import org.apache.spark.SparkContext._'
    - 'import org.apache.spark.SparkConf'
    - 'val conf = new SparkConf(true).set(\"spark.cassandra.connection.host\", \"box1\")' 
    - 'sc.stop'
    - 'val sc = new SparkContext(conf)'
    tags: setup_spark

  - name: set SPARK_HOME and add SPARK_HOME/bin to PATH in /etc/profile.d/local.sh
    lineinfile: dest=/etc/profile.d/local.sh
                line="{{item}}"
                insertafter=EOF
                create=yes
                mode=0755
    with_items: 
    - 'export SPARK_HOME={{spark_dir}}'
    - 'export PATH=$PATH:$SPARK_HOME/bin'
    tags: setup_spark

  - name: set and export SPARK_MASTER in conf/spark-env.sh
    lineinfile: dest={{spark_dir}}/conf/spark-env.sh
          regexp="export SPARK_MASTER"
          line="export SPARK_MASTER={{spark_master_host}}"
          insertafter=EOF
          create=yes
          mode=0755
    tags: setup_spark

  - name: copy log4j.properties.template to log4j.properties
    command: | 
      cp {{spark_dir}}/conf/log4j.properties.template 
         {{spark_dir}}/conf/log4j.properties
    tags: setup_spark

  - name: change log4f.properties
    lineinfile: dest={{spark_dir}}/conf/log4j.properties
                regexp='log4j.rootCategory=INFO, console'
                line='log4j.rootCategory=WARN, console'
    tags: setup_spark
  
  # section: setup_dsc
  #
  # sudo yum install cassandra21-tools
  - name: install dsc service
    yum: name=dsc22
    tags: setup_dsc

  - name: configure /etc/cassandra/conf/cassandra.yaml listen_address
    lineinfile: dest=/etc/cassandra/conf/cassandra.yaml 
                regexp='^listen_address:' 
                line='listen_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dsc

  - name: configure /etc/cassandra/conf/cassandra.yaml listen_address
    lineinfile: dest=/etc/cassandra/conf/cassandra.yaml 
                regexp='^broadcast_address:' 
                line='broadcast_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dsc

  - name: configure /etc/cassandra/conf/cassandra.yaml rpc_address
    lineinfile: dest=/etc/cassandra/conf/cassandra.yaml 
                regexp='^#rpc_address:' 
                line='rpc_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dsc

  - name: configure /etc/cassandra/conf/cassandra.yaml seeds
    lineinfile: dest=/etc/cassandra/conf/cassandra.yaml 
      regexp='^(.*) - seeds:'
      line="\1 - seeds{{colon}} \"{{ groups['cassandra_seed_hosts'] | join(',') }}\""
      backrefs=yes
    tags: setup_dsc


  # section: setup_dse
  #
  - name: install dse service
    yum: name=dse-full
         enablerepo=dse
    tags: setup_dse 

  - name: configure /etc/dse/cassandra/cassandra.yaml listen_address
    lineinfile: dest=/etc/dse/cassandra/cassandra.yaml 
                regexp='^listen_address:' 
                line='listen_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dse

  - name: configure /etc/dse/cassandra/cassandra.yaml listen_address
    lineinfile: dest=/etc/dse/cassandra/cassandra.yaml 
                regexp='^broadcast_address:' 
                line='broadcast_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dse

  - name: configure /etc/dse/cassandra/cassandra.yaml rpc_address
    lineinfile: dest=/etc/dse/cassandra/cassandra.yaml 
                regexp='^#rpc_address:' 
                line='rpc_address{{colon}} {{inventory_hostname}}' #'
    tags: setup_dse

  - name: configure /etc/dse/cassandra/cassandra.yaml seeds
    lineinfile: dest=/etc/dse/cassandra/cassandra.yaml 
      regexp='^(.*) - seeds:'
      line="\1 - seeds{{colon}} \"{{ groups['cassandra_seed_hosts'] | join(',') }}\""
      backrefs=yes
    tags: setup_dse

  - name: set SPARK_ENABLED in /etc/default/dse 
    lineinfile: dest=/etc/default/dse
                regexp=^SPARK_ENABLED=
                line=SPARK_ENABLED={{dse_spark_enabled}}
    tags: setup_dse

  - name: set HADOOP_ENABLED in /etc/default/dse 
    lineinfile: dest=/etc/default/dse
                regexp=^HADOOP_ENABLED=
                line=HADOOP_ENABLED={{dse_hadoop_enabled}}
    tags: setup_dse

  # section: setup_hadoop
  #
  # setup ssh access from master to slaves
  # default port being used (and not specified) in core-sit.xml
  # when starting cluster  rm -Rf /app/hadoop/tmp/*
  # http://Hadoopmaster:50070/ â€“ web UI of the NameNode daemon
  #
  - name: Create user hadoop
    user: name=hadoop
          password={{hadoop_password}}
    tags: setup_hadoop
    
  - name: Create user hdfs
    user: name=hdfs
          group=hadoop
          password={{hdfs_password}}
    tags: setup_hadoop
    
  - name: install hadoop-hdfs-namenode
    yum: name=hadoop-hdfs-namenode
    tags: 
    - setup_hadoop 
    - setup_hadoop_namenode

# - name: install hadoop-0.20-mapreduce-tasktracker 
#   yum: name=hadoop-0.20-mapreduce-tasktracker 
#   tags: setup_hadoop 

  - name: install hadoop-hdfs-datanode
    yum: name=hadoop-hdfs-datanode
    tags: 
    - setup_hadoop
    - setup_hadoop_datanode


  - name: install hadoop-client
    yum: name=hadoop-client
    tags: 
    - setup_hadoop 
    - setup_hadoop_client

  - name: config hadoop - hdfs-site.xml 
    lineinfile: dest=/etc/hadoop/conf/hdfs-site.xml
        regexp="not present in file"
        line="{{item}}"
        insertbefore="</configuration>"
        create=yes
    with_items: 
    - "  <property>"
    - "    <name>dfs.permissions.superusergroup</name>"
    - "    <value>hadoop</value>"
    - "  </property>"
    - "  <property>"
    - "    <name>dfs.namenode.name.dir</name>"
    - "    <value>file:///var/lib/hadoop-hdfs/cache/hdfs/dfs/name</value>"
    - "  </property>"
    - "  <property>"
    - "    <name>dfs.datanode.data.dir</name>"
    - "    <value>file:///var/lib/hadoop-hdfs/cache/hdfs/dfs/data</value>"
    - "  </property>"
    tags: setup_hadoop

  - name: config hadoop - core-site.xml 
    lineinfile: dest=/etc/hadoop/conf/core-site.xml
        regexp="not present in file"
        line="{{item}}"
        insertbefore="</configuration>"
        create=yes
    with_items: 
    - "  <property>"
    - "    <name>fs.defaultFS</name>"
    - "    <value>hdfs://{{hdfs_namenode_host}}/</value>"
    - "  </property>"
    tags: setup_hadoop

  - name: config hadoop - slaves
    lineinfile: dest=/etc/hadoop/conf/slaves
        regexp="localhost"
        state=absent
        create=yes
    tags: setup_hadoop

  - name: config hadoop - slaves
    lineinfile: dest=/etc/hadoop/conf/slaves
        regexp="{{item}}"
        line="{{item}}"
        insertafter=EOF
        create=yes
    with_items: groups['hdfs_datanode_hosts']
    tags: setup_hadoop

  - name: add JAVA_HOME to /etc/hadoop/conf/hadoop-env.sh
    lineinfile: dest=/etc/hadoop/conf/hadoop-env.sh
        regexp="export JAVA_HOME"
        line="export JAVA_HOME={{java18_dir}}"
        insertafter=EOF
        create=yes
    tags: setup_hadoop

  - name: setup hadoop directories
    file: path={{item}}
          state=directory
          owner=hdfs
          mode=0777
    with_items: 
    - "{{hadoop_pid_dir}}"
    - "{{hadoop_log_dir}}"
    tags: setup_hadoop

  - name: setup hdfs directories 
    file: path={{item}}
          state=directory
          owner=hdfs
          group=hdfs
          mode=0777
    with_items: 
    - "{{hadoop_name_dir}}"
    - "{{hadoop_data_dir}}"
    tags: setup_hadoop

  - name: fix HADOOP_IDENT_STRING in hadoop-env.sh
    lineinfile: dest={{hadoop_etc_dir}}/conf/hadoop-env.sh
                regexp='^export HADOOP_IDENT_STRING='
                line='export HADOOP_IDENT_STRING=${HADOOP_IDENT_STRING:-$USER}'
    tags: setup_hadoop

  - name: fix hardcoded PIDFILE in /etc/init.d/hadoop-hdfs-namenode
    file: name=/var/run/hadoop-hdfs
          src=/var/local/hadoop/pid
          state=link
          force=yes
    tags: setup_hadoop
    # see https://issues.cloudera.org/browse/DISTRO-442

  - name: add log4j thing
    lineinfile: dest={{hadoop_etc_dir}}/conf/log4j.properties
                line={{item}}
                insertafter=EOF
    with_items:
    - log4j.appender.DRFAAUDIT=org.apache.log4j.ConsoleAppender 
    - log4j.appender.DRFAAUDIT.layout=org.apache.log4j.PatternLayout
    tags: setup_hadoop

  - name: export LD_LIBRARY_PATH=/usr/lib/hadoop/lib/native/
    lineinfile: dest=/etc/profile.d/local.sh
                line='export LD_LIBRARY_PATH=/usr/lib/hadoop/lib/native/'
                insertafter=
                create=yes
                mode=0755
    tags: setup_hadoop

- hosts: hdfs_namenode_host
  become: true
  become_user: root
  tasks:

  - name: remove hadoop_name_dir
    file: path="{{hadoop_name_dir}}"
          state=absent
    tags: setup_hadoop

  - name: service hadoop-hdfs-namenode init
    shell: "service hadoop-hdfs-namenode init"
    tags: setup_hadoop

- hosts: r_host
  become: true
  become_user: root
  vars_files: 
  - /etc/ansible/vars.yaml
  tasks:

  - name: yum install R
    yum: name=R-devel
         disable_gpg_check=yes
    tags: setup_r

  - name: get rstudio server rpm file
    command: > 
      wget {{rstudio_server_url}} 
        --no-check-certificate 
        --output-document={{rstudio_server_rpm}}
    tags: setup_r

  - name: yum install rstudio-server
    yum: name={{rstudio_server_rpm}}
    tags: 
    - setup_r

  - name: setup R user
    user: name={{r_user_name}}
          password={{r_user_password}}
    tags: setup_r

  - name: connect SparkR to R
    lineinfile: dest=/home/{{r_user_name}}/.Rprofile
        regexp="not present in file"
        line='{{item}}'
        insertbefore=EOF
        create=yes
        owner={{r_user_name}}
    with_items: 
    - '.First <- function(){'
    - ' library("SparkR", lib.loc="{{spark_dir}}/R/lib/")'
    - ' Sys.setenv(SPARK_HOME="{{spark_dir}}")'
    - ' sc <<- sparkR.init(master = "{{spark_master_url}}")'
    - '}'
    tags: setup_r


  - name: Done
    command: echo "Done"
    tags: all
